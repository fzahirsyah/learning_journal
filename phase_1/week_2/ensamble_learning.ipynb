{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##load data\n",
    "iris = load_iris()\n",
    "type(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
       "0                  5.1               3.5                1.4               0.2\n",
       "1                  4.9               3.0                1.4               0.2\n",
       "2                  4.7               3.2                1.3               0.2\n",
       "3                  4.6               3.1                1.5               0.2\n",
       "4                  5.0               3.6                1.4               0.2\n",
       "..                 ...               ...                ...               ...\n",
       "145                6.7               3.0                5.2               2.3\n",
       "146                6.3               2.5                5.0               1.9\n",
       "147                6.5               3.0                5.2               2.0\n",
       "148                6.2               3.4                5.4               2.3\n",
       "149                5.9               3.0                5.1               1.8\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x= iris.data\n",
    "y= iris.target\n",
    "\n",
    "df= pd.DataFrame(x,columns= iris.feature_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     class  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        0  \n",
       "4        0  \n",
       "..     ...  \n",
       "145      2  \n",
       "146      2  \n",
       "147      2  \n",
       "148      2  \n",
       "149      2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df['class'] = y\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:, :4] #  fitur\n",
    "y= new_df['class'] # target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking\n",
    "\n",
    "## Voting Ensemble\n",
    "\n",
    "atau majority voting ensembles adalah ML ensemble model yang mengkombinasikan prediksi dari beberapa model lain. Digunakan untuk improve predictions\n",
    "\n",
    "Bisa digunakan untuk klasifikasi dan regresi. Dalam kasus **regresi**, ikut mengkalkulasikan **rata-rata dari prediksi tiap model**. Dalam kasus **klasifikasi**, prediksi dari tiap label dijumlahkan dan label dengan **vote terbanyak yang terpilih**\n",
    "\n",
    "**Hard Voting** : Memprediksi kelas dengan jumlah vote terbesar\n",
    "**Soft Voting** : Memprediksi kelas dengan jumlah probabilitas terbesar\n",
    "\n",
    "*Kapan menggunakan Voting ensemble?*\n",
    "\n",
    "- Menghasilkan performance yang lebih baik dibandingkan model lain yang digunakan pada saat ensemble\n",
    "- Menghasilkan varians yang lebih rendah dibandingkan model lain yg digunakan pada saat ensemble\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(random_state=42))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9111111111111111\n",
      "RandomForestClassifier 0.8888888888888888\n",
      "SVC 0.9333333333333333\n",
      "VotingClassifier 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Soft voting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr', LogisticRegression(random_state=42)),\n",
       "                             ('rf', RandomForestClassifier(random_state=42)),\n",
       "                             ('svc', SVC(probability=True, random_state=42))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.9111111111111111\n",
      "RandomForestClassifier 0.8888888888888888\n",
      "SVC 0.9333333333333333\n",
      "VotingClassifier 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Ensemble Learning (Bagging)\n",
    "\n",
    "Bagging mengurangi error learning/varians dengan mengimplementasikan algoritma machine learning yg sama (cth. Random Forest terdiri dari algoritma decision tree)\n",
    "\n",
    "intinya, bagging menggunakan beberapa base learners (contohnya decision tree) yang di train secara terpisah dengan random sample dari training set. Dengan menggunakan voting atau mengambil rerata dari hasil nya akan menghsilkan model yang akurat dan stabil.\n",
    "\n",
    "https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42)\n",
    "#n_estimators : berapa banyak tree\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanpa bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "Disadventages of Decision Tree\n",
    "1. Kalo tree depth nya maksimum (default setting), akan nge capture semua details di training set\n",
    "2. ketika di apply ke data test akan ngasih nilai error yang tinggi karena varians yang tinggi (Overfit to Training data)\n",
    "\n",
    "Random Forests atau Random Decision Forests adalah metode ensemble learning untuk klasifikasi dan regresi yang beroperasi dengan membangun beberapa decision tree yang independen (menggunakan bootstrap) dan hasil ouput nya dengan cara mengambil keputusan terbanyak dari semua hasil prediksi sebagai final output.\n",
    "\n",
    "Random forests dapat mengurangi overfitting/varians dengan mengeneralisir pola data nya dibandingkan mempelajari pola datanya\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.datasets import make_moons\n",
    "\n",
    "# X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_pred == y_pred_rf) / len(y_pred)  # very similar predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "artinya penerapan bagging di decision tree similar dengan random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Salah satu metode dalam feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.11249225099876375\n",
      "sepal width (cm) 0.02311928828251033\n",
      "petal length (cm) 0.4410304643639577\n",
      "petal width (cm) 0.4233579963547682\n"
     ]
    }
   ],
   "source": [
    "#misal dengan dataset iris\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, random_state=42)\n",
    "rnd_clf.fit(iris[\"data\"], iris[\"target\"])\n",
    "for name, score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11249225, 0.02311929, 0.44103046, 0.423358  ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plotting feature importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = iris['feature_names']\n",
    "importances = rnd_clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Out of Bag Evaluation**\n",
    "\n",
    "Salah satu metode validasi yang dipakai random forest untuk meminimalisir hasil varians yg tinggi\n",
    "\n",
    "Advantages of OOB\n",
    "\n",
    "1. Tidak ada data yang leak, model divalidasi hanya dengan OOB sample, sehingga data tidak digunakan pada training model.\n",
    "2. Less Variance\n",
    "3. Better Predictive Model\n",
    "4. Less Computation\n",
    "\n",
    "Disadvantages of OOB\n",
    "\n",
    "1. Time consuming\n",
    "2. Tidak untuk dataset yang besar\n",
    "3. paling baik digunakan pada dataset yang kecil-medium\n",
    "\n",
    "\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2020/12/out-of-bag-oob-score-in-the-random-forest-algorithm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9523809523809523"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    bootstrap=True, oob_score=True, random_state=40)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_clf.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9111111111111111"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = bag_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential Ensemble Learning (Boosting)\n",
    "\n",
    " Boosting berbanding terbalik dengan bagging. Kalau di bagging, tiap base learners nya itu independent tapi kalo di boosting tiap base learners nya saling dependent. Dengan mencoba untuk meng improve atau mengoreksi kesalahan pada base learner sebelumnya.\n",
    " \n",
    " Mengurangi bias\n",
    "\n",
    " Algoritma boosting lainnya: Adaboost (Adaptive Boosting), XGBoost (Extreme Gradient Boosting), Catboost, LightGBM.\n",
    "\n",
    " Perbedaan dari masing2 metode adalah dari bagaimana error nya ditanggulangi (seperti me-modify weights atau mengurangi loss function)\n",
    " \n",
    " https://towardsdatascience.com/ensemble-learning-bagging-boosting-3098079e5422\n",
    " \n",
    "## Adaboost\n",
    "\n",
    "Mengimplementasikan vector of weights untuk menanggulangi sample yang salah diprediksi(dengan meningkatkan weight nya) dan memberi reward bagi sample yang benar diprediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=3), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)\n",
    "\n",
    "#Learning rate: semakin besar nilai learning rate semakin cepat processing time, range 0-1, \\\n",
    "    # Semakin kecil learning rate nya semakin lama tapi hasilnya bagus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAMME (yang merupakan singkatan dari Stagewise Additive Modeling using a Multiclass Exponential loss function). Ketika hanya ada dua kelas, SAMME equivalent dengan AdaBoost. \n",
    "Jika prediktor dapat memperkirakan probabilitas kelas (yaitu, jika mereka memiliki metode predict_proba()), Scikit-Learn dapat menggunakan varian SAMME yang disebut SAMME.R (R singkatan dari “Real”), yang bergantung pada probabilitas kelas daripada prediksi dan umumnya berkinerja lebih baik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate, merupakan salah satu parameter training untuk menghitung nilai koreksi bobot pada waktu proses training. Nilai learning rate ini berada pada range nol (0) sampai (1). **Semakin besar nilai learning rate**, maka proses training akan berjalan **semakin cepat**. Semakin besar learning rate, maka **accuracy akan cenderung semakin berkurang**, tetapi berlaku sebaliknya, apabila learning rate-nya semakin kecil, maka accuracy akan semakin besar atau bertambah dengan konsekuensi proses training akan memakan waktu yang semakin lama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME',\n",
       "                   base_estimator=DecisionTreeClassifier(max_depth=3),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=3), n_estimators=200,\n",
    "    algorithm=\"SAMME\", learning_rate=0.5, random_state=42)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = ada_clf.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Implementaisnya dengan mengkalkulasikan gradient untuk mengoptimasi loss function nya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:10:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_reg = XGBClassifier(n_estimators=200,random_state=42)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_reg.predict(X_test)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:10:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost's prediction accuracy is: 93.33\n",
      "Time consumed for training: 0.092\n",
      "Time consumed for prediction: 0.00243 seconds\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(n_estimators=200, random_state=42)\n",
    "training_start = time.perf_counter()\n",
    "xgb.fit(X_train, y_train)\n",
    "training_end = time.perf_counter()\n",
    "prediction_start = time.perf_counter()\n",
    "preds = xgb.predict(X_test)\n",
    "prediction_end = time.perf_counter()\n",
    "acc_xgb = (preds == y_test).sum().astype(float) / len(preds)*100\n",
    "xgb_train_time = training_end-training_start\n",
    "xgb_prediction_time = prediction_end-prediction_start\n",
    "print(\"XGBoost's prediction accuracy is: %3.2f\" % (acc_xgb))\n",
    "print(\"Time consumed for training: %4.3f\" % (xgb_train_time))\n",
    "print(\"Time consumed for prediction: %6.5f seconds\" % (xgb_prediction_time))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d62006d1f3422635846181a997a61e8ec3049f797e5d7dfe0cd1bb84092b7c19"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
